{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f6c2a0c-425a-40ec-a9a2-7d88ed7d1403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import textwrap\n",
    "import sys\n",
    "import langchain\n",
    "import torch\n",
    "import faiss\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader, UnstructuredPDFLoader, PyPDFLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "from huggingface_hub import notebook_login\n",
    "from langchain import HuggingFacePipeline, PromptTemplate\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader, DirectoryLoader\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "import textwrap\n",
    "import torch\n",
    "import langchain\n",
    "import langchain_core\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pdf2image import convert_from_path\n",
    "from qdrant_client import qdrant_client\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "import torch\n",
    "import langchain\n",
    "import langchain_core\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a89857a-aa8a-4205-b824-d2cb18f84555",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"QDRANT_HOST\"] = \"https://ef3d190d-4471-4044-b8a5-6aba8c656aa8.us-east4-0.gcp.cloud.qdrant.io:6333\"\n",
    "os.environ[\"QDRANT_API_KEY\"] = \"EPOl1GIG9WTr2joExRzwjRkk5LuLWNvImfgU4y2GPaN_Nu5kWcs51w\"\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "301ee911-d450-457e-831e-ae90677347fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = qdrant_client.QdrantClient(\n",
    "    url=os.getenv(\"QDRANT_HOST\"),\n",
    "    api_key = os.getenv(\"QDRANT_API_KEY\")\n",
    ")\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name = 'keepitreal/vietnamese-sbert')\n",
    "doc_store = Qdrant(\n",
    "    client=client, collection_name=\"Pengi-Doc\", \n",
    "    embeddings=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3834d4c4-1a5c-4b3c-bb4f-81866bb7c7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "d:\\enviroments\\envs\\pytorch\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:466: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96757a31fb0b4112ae7eed2a589af554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"vilm/vinallama-7b-chat\", token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\"))\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"vilm/vinallama-7b-chat\",\n",
    "                                             device_map='cuda:0',\n",
    "                                             torch_dtype=torch.float16,\n",
    "                                            #  load_in_4bit=True\n",
    "                                             load_in_8bit=True,\n",
    "                                             use_auth_token=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\"))\n",
    "\n",
    "\n",
    "pipe = pipeline(\"text-generation\",\n",
    "                model= model,\n",
    "                tokenizer= tokenizer,\n",
    "                torch_dtype= torch.bfloat16,\n",
    "                device_map= \"auto\",\n",
    "                max_new_tokens = 512,\n",
    "                do_sample = True,\n",
    "                top_k = 15,\n",
    "                num_return_sequences=1,\n",
    "                eos_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe, model_kwargs={\"temperature\": 0.05})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d9ffe96-48be-43e6-bf4c-fb85575f25fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"<|im_start|>system\\nSử dụng thông tin sau đây để trả lời câu hỏi. Nếu bạn không biết câu trả lời, hãy nói không biết, đừng cố tạo ra câu trả lời\\n\n",
    "{context}<|im_end|>\\n<|im_start|>user\\n{question}<|im_end|>\\n<|im_start|>assitant\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type='stuff',  # Change 'stuff' to a valid chain type\n",
    "    retriever=doc_store.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    verbose=True,\n",
    "    chain_type_kwargs={\n",
    "        \"verbose\": True,\n",
    "        \"prompt\": QA_CHAIN_PROMPT\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e6d0b02-ec8b-4ff3-8bf8-543d435bca30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b243fb30-37a4-420d-a3e5-96165c513f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<|im_start|>system\n",
      "Sử dụng thông tin sau đây để trả lời câu hỏi. Nếu bạn không biết câu trả lời, hãy nói không biết, đừng cố tạo ra câu trả lời\n",
      "\n",
      "TS. Nguyễn Kim Ánh\n",
      "\n",
      "TS. Nguyễn Xuân Phong\n",
      "\n",
      "3.  Ban lãnh đạo tiền nhiệm\n",
      "\n",
      "Hội đồng Quản trị:\n",
      "\n",
      "Chủ tịch HĐQT: Trương Gia Bình (2006-2011), Lê Trường Tùng (2011-)\n",
      "\n",
      "Phó Chủ tịch HĐQT: TS. Lê Trường Tùng, TS. Nguyễn Thành Nam và\n",
      "\n",
      "các ủy viên gồm có: Bùi Quang Ngọc và Nguyễn Khắc Thành.\n",
      "\n",
      "Ban giám hiệu:\n",
      "\n",
      "Hiệu trưởng: TS. Lê Trường Tùng (2006-2014), TS. Đàm Quang Minh\n",
      "\n",
      "(2014-2016)\n",
      "\n",
      "Các Phó Hiệu trưởng:\n",
      "\n",
      "TS. Nguyễn Khắc Thành\n",
      "\n",
      "TS. Nguyễn Kim Ánh\n",
      "\n",
      "ThS. Nguyễn Xuân Phong\n",
      "\n",
      "TS. Nguyễn Việt Thắng\n",
      "\n",
      "TS. Nguyễn Khắc Thành\n",
      "\n",
      "TS. Nguyễn Kim Ánh\n",
      "\n",
      "ThS. Nguyễn Xuân Phong\n",
      "\n",
      "TS. Nguyễn Việt Thắng\n",
      "\n",
      "4.  Mục tiêu phát triển\n",
      "\n",
      "Sứ mệnh của trường đại học FPT là đào tạo những nhân tài chất lượng góp phần\n",
      "\n",
      "đáp ứng thị trường lao động trong nước và quốc tế. Vậy trường FPT học về gì?\n",
      "\n",
      "Chương trình đào tạo chính của FPT là Công nghệ thông tin, tài chính, kinh tế.\n",
      "\n",
      "Ngoài ra, trường còn đào tạo các ngành ngôn ngữ Nhật, Anh và Hàn Quốc. Tính\n",
      "\n",
      "2.  Ban lãnh đạo đương nhiệm\n",
      "\n",
      "Hội đồng Quản trị:\n",
      "\n",
      "Chủ tịch HĐQT: TS. Lê Trường Tùng\n",
      "\n",
      "Phó Chủ tịch HĐQT: TS. Nguyễn Thành Nam và các ủy viên gồm có\n",
      "\n",
      "Trương Gia Bình, Bùi Quang Ngọc, Nguyễn Khắc Thành, Nguyễn Kim\n",
      "\n",
      "Ánh, Phan Trường Lâm\n",
      "\n",
      "Ban giám hiệu trường FPT:\n",
      "\n",
      "Hiệu trưởng: TS. Nguyễn Khắc Thành\n",
      "\n",
      "Các Phó Hiệu trưởng trường FPT:\n",
      "\n",
      "TS. Trần Ngọc Tuấn\n",
      "\n",
      "TS. Nguyễn Việt Thắng\n",
      "\n",
      "TS. Nguyễn Kim Ánh\n",
      "\n",
      "TS. Nguyễn Xuân Phong\n",
      "\n",
      "3.  Ban lãnh đạo tiền nhiệm\n",
      "\n",
      "Hội đồng Quản trị:<|im_end|>\n",
      "<|im_start|>user\n",
      "Minh Hoàng là ai?<|im_end|>\n",
      "<|im_start|>assitant\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\enviroments\\envs\\pytorch\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:671: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'query': 'Minh Hoàng là ai?', 'result': '\\nMinh Hoàng không được đề cập trong thông tin cung cấp.'}\n",
      "--- Inference time: 13.602863550186157 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "print(qa_chain.invoke(\"Minh Hoàng là ai?\"))\n",
    "# print(device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "print(\"--- Inference time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4898c4c8-f9ae-4852-a891-4e8aef17bac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<|im_start|>system\n",
      "Sử dụng thông tin sau đây để trả lời câu hỏi. Nếu bạn không biết câu trả lời, hãy nói không biết, đừng cố tạo ra câu trả lời\n",
      "\n",
      "tham gia sẽ thành thạo tiếng Nhật để có thể học tập và làm việc tốt trong môi trường\n",
      "\n",
      "tiếng Nhật. Ngoài ra, học viên còn có cơ hội thực tập hoặc làm việc ở các công ty tại\n",
      "\n",
      "Nhật Bản sau khi kết thúc khóa học.\n",
      "\n",
      "Ngày nay, trường đại học Kyoto trở thành sự lựa chọn hàng đầu cho các sinh viên\n",
      "\n",
      "quốc tế đến từ khắp nơi trên thế giới khi họ có ý định học chuyên sâu về tiếng Nhật\n",
      "\n",
      "cũng như văn hóa Nhật Bản. Điểm đặc biệt ở Trường Kyoto là mỗi lớp học đều có sự\n",
      "\n",
      "Á\n",
      "\n",
      "ASOCIO (Asian-Oceanian Computing Industry Organization) là Tổ chức Công nghiệp\n",
      "\n",
      "điện toán Châu Á – Châu Đại Dương đã được thành lập hơn 30 năm.\n",
      "\n",
      "Trong khuôn khổ Hội nghị Thượng đỉnh Số ASOCIO 2018 (TP. Tokyo, Nhật Bản) vào\n",
      "\n",
      "ngày 7-8/11/2018, Hội đồng giải thưởng ASOCIO 2018 đã quyết định trao giải cho Đại\n",
      "\n",
      "học FPT tại hạng mục Đơn vị Đào tạo Công nghệ thông tin xuất sắc (ICT Education). Đại\n",
      "\n",
      "học FPT là đơn vị giáo dục thứ 2 của Việt Nam vinh dự nhận giải thưởng ASOCIO.\n",
      "\n",
      "V.\n",
      "\n",
      "năng lực ngôn ngữ chung Châu Âu (CEFR)\n",
      "\n",
      "II.  Ngành Ngôn ngữ Nhật\n",
      "\n",
      "Ngành Ngôn ngữ Nhật – Chuyên ngành Song ngữ Nhật – Anh là ngành học\n",
      "\n",
      "đào tạo sinh viên có khả năng sử dụng thành thạo hai ngôn ngữ Nhật và Anh,\n",
      "\n",
      "đồng thời có kiến thức và kỹ năng cần thiết để làm việc trong các lĩnh vực liên\n",
      "\n",
      "quan đến ngôn ngữ và văn hóa.\n",
      "\n",
      "Chương trình Cử nhân Ngôn ngữ Nhật – Chuyên ngành Song ngữ Nhật – Anh\n",
      "\n",
      "đào tạo người học trở thành các công dân toàn cầu với khả năng sử dụng linh<|im_end|>\n",
      "<|im_start|>user\n",
      "Yasuo là ai?<|im_end|>\n",
      "<|im_start|>assitant\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'query': 'Yasuo là ai?', 'result': '\\nKhông có thông tin nào được cung cấp về một người tên là Yasuo. Bạn có thể cung cấp thêm ngữ cảnh hoặc thông tin về Yasuo để tôi có thể hỗ trợ bạn tốt hơn không?'}\n",
      "--- Inference time: 23.815552473068237 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "print(qa_chain.invoke(\"Yasuo là ai?\"))\n",
    "# print(device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "print(\"--- Inference time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73c75ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<|im_start|>system\n",
      "Sử dụng thông tin sau đây để trả lời câu hỏi. Nếu bạn không biết câu trả lời, hãy nói không biết, đừng cố tạo ra câu trả lời\n",
      "\n",
      "Màu cam tượng trưng cho sự sáng tạo, sinh lực và chia sẻ cộng đồng. Màu xanh lá\n",
      "\n",
      "cây đại diện cho sự phát triển, thay đổi. Màu xanh dương đậm biểu tượng cho sự\n",
      "\n",
      "bền vững, trí tuệ và thống nhất.\n",
      "\n",
      "Logo trường FPT có những nét cong mềm mại dựa trên những đường tròn hội tụ\n",
      "\n",
      "với ý nghĩa lan tỏa sức mạnh của công nghệ tới cộng đồng. Những đường cong có\n",
      "\n",
      "xu hướng vươn cao, liên tiếp chuyển động tựa như những ngọn lửa bập bùng đầy\n",
      "\n",
      "sức sống và sự năng động.\n",
      "\n",
      "hiệu quả kho báu này. Nhân lực của ngành không chỉ là những chuyên gia Công\n",
      "\n",
      "nghệ thông tin, mà còn là những nhà sáng tạo thông tin, xây dựng giải pháp độc\n",
      "\n",
      "đáo.\n",
      "\n",
      "Với sự bùng nổ của di động, trí tuệ nhân tạo và big data, ngành Hệ thống Thông\n",
      "\n",
      "tin mở ra những cơ hội nghề nghiệp chưa từng có. Từ quản trị cơ sở dữ liệu đến\n",
      "\n",
      "chuyên gia phân tích Hệ thống Thông tin, những người lựa chọn lĩnh vực này\n",
      "\n",
      "không chỉ đang đối mặt với những thách thức mà còn có cơ hội tỏa sáng trong\n",
      "\n",
      "tạo và khả năng tự tạo động lực cho bản thân liên tục, nhằm giúp sản phẩm tạo ra\n",
      "\n",
      "độc đáo và mang dấu ấn riêng, nhất là trong thời đại AI được tích hợp sâu vào các\n",
      "\n",
      "hoạt động Marketing.\n",
      "\n",
      "Bên cạnh, người làm Marketing cần có khả năng làm việc nhóm, khả năng giao\n",
      "\n",
      "tiếp tốt nhằm đảm bảo truyền tải được thông điệp hiệu quả đến các đối tượng mục\n",
      "\n",
      "tiêu.\n",
      "\n",
      "Tuy Marketing thường được mặc định là lãnh địa cho sự sáng tạo, thế nhưng<|im_end|>\n",
      "<|im_start|>user\n",
      "Thế nào là một người cố chấp?<|im_end|>\n",
      "<|im_start|>assitant\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'query': 'Thế nào là một người cố chấp?', 'result': '\\nMột người cố chấp là một người không sẵn lòng thay đổi quan điểm, ý kiến hoặc hành vi của họ ngay cả khi đối mặt với bằng chứng mâu thuẫn. Họ có xu hướng bám vào niềm tin hoặc giả định của họ, ngay cả khi chúng không được chứng minh bằng bằng chứng hoặc có thể được sửa đổi bởi thông tin mới. Sự cố chấp này có thể gây trở ngại cho việc ra quyết định hợp lý, giao tiếp và giải quyết vấn đề.'}\n",
      "--- Inference time: 42.32711315155029 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "print(qa_chain.invoke(\"Thế nào là một người cố chấp?\"))\n",
    "# print(device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "print(\"--- Inference time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "839a829a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<|im_start|>system\n",
      "Sử dụng thông tin sau đây để trả lời câu hỏi. Nếu bạn không biết câu trả lời, hãy nói không biết, đừng cố tạo ra câu trả lời\n",
      "\n",
      "Ngoài đào tạo hệ phổ thông trung học với chất lượng cao, Đại học FPT là nơi đào tạo\n",
      "\n",
      "và cung cấp nguồn nhân lực chất lượng cao chuyên ngành Công nghệ thông tin, Khối\n",
      "\n",
      "ngành Kinh tế, Thiết kế đồ họa, Ngôn ngữ, Kiến trúc, Quản trị khách sạn và các\n",
      "\n",
      "nhóm ngành khác có liên quan cho Tập đoàn FPT cũng như cho các tập đoàn toàn cầu\n",
      "\n",
      "tại khắp nơi trên thế giới và các doanh nghiệp Việt Nam.\n",
      "\n",
      "Sự khác biệt của Đại học FPT so với các trường đại học khác là là đào tạo theo hình\n",
      "\n",
      "TS. Nguyễn Khắc Thành\n",
      "\n",
      "TS. Nguyễn Kim Ánh\n",
      "\n",
      "ThS. Nguyễn Xuân Phong\n",
      "\n",
      "TS. Nguyễn Việt Thắng\n",
      "\n",
      "4.  Mục tiêu phát triển\n",
      "\n",
      "Sứ mệnh của trường đại học FPT là đào tạo những nhân tài chất lượng góp phần\n",
      "\n",
      "đáp ứng thị trường lao động trong nước và quốc tế. Vậy trường FPT học về gì?\n",
      "\n",
      "Chương trình đào tạo chính của FPT là Công nghệ thông tin, tài chính, kinh tế.\n",
      "\n",
      "Ngoài ra, trường còn đào tạo các ngành ngôn ngữ Nhật, Anh và Hàn Quốc. Tính\n",
      "\n",
      "Nhà trường chú trọng kết nối sinh viên với doanh nghiệp giúp người học có cơ\n",
      "\n",
      "hội tiếp cận, trau dồi nghiệp vụ từ khi còn ngồi trên ghế nhà trường. Sinh viên Đại\n",
      "\n",
      "học FPT được tham gia Học kỳ đào tạo trong doanh nghiệp (OJT) ở học kỳ 6\n",
      "\n",
      "chuyên ngành tại các doanh nghiệp:  FPT Securities , Amazing Tech, FPT\n",
      "\n",
      "Software, FPT Retail, FPT Telecom, VnExpress, TPBank, FPT Online, FPT\n",
      "\n",
      "Sendo, FPT Securities, Amazing Tech, Đài Truyền hình TP. HCM (HTV), Idp<|im_end|>\n",
      "<|im_start|>user\n",
      "đại học FPT bao gồm những chuyên ngành nào?<|im_end|>\n",
      "<|im_start|>assitant\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'query': 'đại học FPT bao gồm những chuyên ngành nào?', 'result': '\\nĐại học FPT cung cấp nhiều chuyên ngành, bao gồm:\\n\\n1. Công nghệ thông tin\\n2. Tài chính\\n3. Kinh tế\\n4. Thiết kế đồ họa\\n5. Ngôn ngữ (Nhật, Anh, Hàn)\\n6. Kiến trúc\\n7. Quản trị khách sạn\\n\\nNgoài ra, họ còn cung cấp các chuyên ngành liên quan khác như Kỹ thuật phần mềm, Khoa học dữ liệu, Trí tuệ nhân tạo và Điện toán đám mây.'}\n",
      "--- Inference time: 38.115190267562866 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "print(qa_chain.invoke(\"đại học FPT bao gồm những chuyên ngành nào?\"))\n",
    "# print(device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "print(\"--- Inference time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a31a56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<|im_start|>system\n",
      "Sử dụng thông tin sau đây để trả lời câu hỏi. Nếu bạn không biết câu trả lời, hãy nói không biết, đừng cố tạo ra câu trả lời\n",
      "\n",
      "cầu thị trường\n",
      "\n",
      "Phương pháp đào tạo thực chiến kết hợp với công nghệ AI. Bên cạnh, thông\n",
      "\n",
      "qua các học phần, hoạt động cộng đồng ngoại ngữ; đồng thời, được trải\n",
      "\n",
      "nghiệm một học kỳ tiếng Anh tại nước ngoài, cùng với ít nhất 1 học kỳ\n",
      "\n",
      "chuyên ngành nước ngoài. Sinh viên Đại học FPT trưởng thành dần sau quá\n",
      "\n",
      "trình học tập và thực chiến, đặc biệt là trong học kỳ được đào tạo thực tế tại\n",
      "\n",
      "doanh nghiệp trong hoặc ngoài nước như: Amazon Webs Services (Aws),\n",
      "\n",
      "Trí tuệ nhân tạo\n",
      "\n",
      "Hệ thống thông tin\n",
      "\n",
      "\n",
      "\n",
      "Thiết kế đồ họa\n",
      "\n",
      "Quản trị truyền thông\n",
      "\n",
      "Digital Marketing\n",
      "\n",
      "Kinh doanh quốc tế\n",
      "\n",
      "Ngôn ngữ Anh\n",
      "\n",
      "Ngôn ngữ Nhật\n",
      "\n",
      "Quản trị khách sạn\n",
      "\n",
      "Quản trị dịch vụ du lịch và lữ hành\n",
      "\n",
      "7.  Các giai đoạn đào tạo chính trong chương trình đào tạo đại học chính quy\n",
      "\n",
      "Trường Đại học FPT có nhiều chương trình đào tạo khác nhau như Đại học, sau\n",
      "\n",
      "đại học, các chương trình liên kết quốc tế. Chương trình đào tạo hệ đại học của\n",
      "\n",
      "nghiệp đầu ngành như FPT Software, FPT IS, Long Châu, FPT Retail,\n",
      "\n",
      "FPT Telecom, FPT Online, FPT Sendo, FPT Securities , Amazing Tech,\n",
      "\n",
      "Đài Truyền hình TP. HCM (HTV), Idp Education, Tanigawa Vietnam, Jw\n",
      "\n",
      "Marriott – Sun Group (Phú Quốc), HPT Vietnam Corporation… và hơn\n",
      "\n",
      "300 doanh nghiệp là đối tác của Tập đoàn FPT trên toàn thế giới.\n",
      "\n",
      "Học kỳ 7: Sinh viên có kiến thức và kỹ năng chuyên môn sâu về quản lý\n",
      "\n",
      "logistics và chuỗi cung ứng, quản lý rủi ro và chất lượng, thiết kế chuỗi<|im_end|>\n",
      "<|im_start|>user\n",
      "đại học FPT có dịch vụ kí túc xá không?<|im_end|>\n",
      "<|im_start|>assitant\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'query': 'đại học FPT có dịch vụ kí túc xá không?', 'result': '\\nKhông có thông tin về việc Đại học FPT cung cấp ký túc xá trong các thông tin đã cho.'}\n",
      "--- Inference time: 13.30081558227539 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "print(qa_chain.invoke(\"đại học FPT có dịch vụ kí túc xá không?\"))\n",
    "# print(device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "print(\"--- Inference time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3b087ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<|im_start|>system\n",
      "Sử dụng thông tin sau đây để trả lời câu hỏi. Nếu bạn không biết câu trả lời, hãy nói không biết, đừng cố tạo ra câu trả lời\n",
      "\n",
      "Nhà trường chú trọng kết nối sinh viên với doanh nghiệp giúp người học có cơ\n",
      "\n",
      "hội tiếp cận, trau dồi nghiệp vụ từ khi còn ngồi trên ghế nhà trường. Sinh viên Đại\n",
      "\n",
      "học FPT được tham gia Học kỳ đào tạo trong doanh nghiệp (OJT) ở học kỳ 6\n",
      "\n",
      "chuyên ngành tại các doanh nghiệp:  FPT Securities , Amazing Tech, FPT\n",
      "\n",
      "Software, FPT Retail, FPT Telecom, VnExpress, TPBank, FPT Online, FPT\n",
      "\n",
      "Sendo, FPT Securities, Amazing Tech, Đài Truyền hình TP. HCM (HTV), Idp\n",
      "\n",
      "nghiệp đầu ngành như FPT Software, FPT IS, Long Châu, FPT Retail,\n",
      "\n",
      "FPT Telecom, FPT Online, FPT Sendo, FPT Securities , Amazing Tech,\n",
      "\n",
      "Đài Truyền hình TP. HCM (HTV), Idp Education, Tanigawa Vietnam, Jw\n",
      "\n",
      "Marriott – Sun Group (Phú Quốc), HPT Vietnam Corporation… và hơn\n",
      "\n",
      "300 doanh nghiệp là đối tác của Tập đoàn FPT trên toàn thế giới.\n",
      "\n",
      "Học kỳ 7: Sinh viên có kiến thức và kỹ năng chuyên môn sâu về quản lý\n",
      "\n",
      "logistics và chuỗi cung ứng, quản lý rủi ro và chất lượng, thiết kế chuỗi\n",
      "\n",
      "Nam, Saigonlab, Gia Cát Lợi, Ngân Hàng Hàng Hải, Elca Việt Nam, FPT Online,\n",
      "\n",
      "FPT Sendo, FPT Securities, Amazing Tech, Đài Truyền hình TP. HCM (HTV),\n",
      "\n",
      "Idp Education, Tanigawa Vietnam, FPT Software, FPT IS, Long Châu, FPT\n",
      "\n",
      "Retail, FPT Telecom, Jw Marriott – Sun Group, HPT Vietnam Corporation… và\n",
      "\n",
      "hơn 300 doanh nghiệp đối tác của Tập đoàn FPT trên toàn thế giới.\n",
      "\n",
      "Bên cạnh, thông qua các học phần, hoạt động cộng đồng ngoại ngữ; đồng thời,<|im_end|>\n",
      "<|im_start|>user\n",
      "Học phí của FPT có quá cao?<|im_end|>\n",
      "<|im_start|>assitant\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'query': 'Học phí của FPT có quá cao?', 'result': '\\nKhông có thông tin cụ thể về học phí của FPT, nhưng thông tin cung cấp cho thấy có các đối tác với hơn 300 doanh nghiệp đối tác trên toàn thế giới và một loạt các học kỳ chuyên ngành, ngụ ý rằng học phí có thể không quá cao, vì các doanh nghiệp này và các học kỳ chuyên ngành này có thể cung cấp cơ hội quý giá để sinh viên tích luỹ kiến thức và kinh nghiệm thực tế.'}\n",
      "--- Inference time: 37.923540353775024 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "print(qa_chain.invoke(\"Học phí của FPT có quá cao?\"))\n",
    "# print(device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "print(\"--- Inference time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4728c3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
