{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f6c2a0c-425a-40ec-a9a2-7d88ed7d1403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import textwrap\n",
    "import sys\n",
    "import langchain\n",
    "import torch\n",
    "import faiss\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader, UnstructuredPDFLoader, PyPDFLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "from huggingface_hub import notebook_login\n",
    "from langchain import HuggingFacePipeline, PromptTemplate\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader, DirectoryLoader\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "import textwrap\n",
    "import torch\n",
    "import langchain\n",
    "import langchain_core\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pdf2image import convert_from_path\n",
    "from qdrant_client import qdrant_client\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "import torch\n",
    "import langchain\n",
    "import langchain_core\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a89857a-aa8a-4205-b824-d2cb18f84555",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"QDRANT_HOST\"] = \"https://ef3d190d-4471-4044-b8a5-6aba8c656aa8.us-east4-0.gcp.cloud.qdrant.io:6333\"\n",
    "os.environ[\"QDRANT_API_KEY\"] = \"EPOl1GIG9WTr2joExRzwjRkk5LuLWNvImfgU4y2GPaN_Nu5kWcs51w\"\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "301ee911-d450-457e-831e-ae90677347fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = qdrant_client.QdrantClient(\n",
    "    url=os.getenv(\"QDRANT_HOST\"),\n",
    "    api_key = os.getenv(\"QDRANT_API_KEY\")\n",
    ")\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name = 'keepitreal/vietnamese-sbert')\n",
    "doc_store = Qdrant(\n",
    "    client=client, collection_name=\"Pengi-Doc\", \n",
    "    embeddings=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3834d4c4-1a5c-4b3c-bb4f-81866bb7c7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "D:\\enviroments\\envs\\pytorch\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:466: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e2866ff2954276a87ab3686002631a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"vilm/vinallama-7b-chat\", token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\"))\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"vilm/vinallama-7b-chat\",\n",
    "                                             device_map='cuda:0',\n",
    "                                             torch_dtype=torch.float16,\n",
    "                                            #  load_in_4bit=True\n",
    "                                             load_in_8bit=True,\n",
    "                                             use_auth_token=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\"))\n",
    "\n",
    "\n",
    "pipe = pipeline(\"text-generation\",\n",
    "                model= model,\n",
    "                tokenizer= tokenizer,\n",
    "                torch_dtype= torch.bfloat16,\n",
    "                device_map= \"auto\",\n",
    "                max_new_tokens = 512,\n",
    "                do_sample = True,\n",
    "                top_k = 15,\n",
    "                num_return_sequences=1,\n",
    "                eos_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe, model_kwargs={\"temperature\": 0.05})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d9ffe96-48be-43e6-bf4c-fb85575f25fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"<|im_start|>system\\nSử dụng thông tin sau đây để trả lời câu hỏi. Nếu bạn không biết câu trả lời, hãy nói không biết, đừng cố tạo ra câu trả lời\\n\n",
    "{context}<|im_end|>\\n<|im_start|>user\\n{question}<|im_end|>\\n<|im_start|>assitant\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type='stuff',  # Change 'stuff' to a valid chain type\n",
    "    retriever=doc_store.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    verbose=True,\n",
    "    chain_type_kwargs={\n",
    "        \"verbose\": True,\n",
    "        \"prompt\": QA_CHAIN_PROMPT\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e6d0b02-ec8b-4ff3-8bf8-543d435bca30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b243fb30-37a4-420d-a3e5-96165c513f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<|im_start|>system\n",
      "Sử dụng thông tin sau đây để trả lời câu hỏi. Nếu bạn không biết câu trả lời, hãy nói không biết, đừng cố tạo ra câu trả lời\n",
      "\n",
      "triển sự nghiệp toàn cầu.\n",
      "\n",
      "c)  Học cùng chuyên gia và doanh nghiệp đồng hành\n",
      "\n",
      "Từ lợi thế thành viên Tập đoàn công nghệ FPT, chương trình đào tạo chuyên\n",
      "\n",
      "ngành Kỹ thuật phần mềm tại trường Đại học FPT được thiết kế theo hướng ứng\n",
      "\n",
      "dụng, tập trung vào các kỹ năng thực hành. Doanh nghiệp tham gia đào tạo sinh\n",
      "\n",
      "viên thông qua hội thảo, dự án và học cùng chuyên gia. Sinh viên tham gia làm dự\n",
      "\n",
      "án và có học kỳ được đào tạo bởi doanh nghiệp (On The Job training) như FPT\n",
      "\n",
      "viên trong thế giới đầy thách thức của Trí tuệ Nhân tạo.\n",
      "\n",
      "Chương trình đào tạo chuyên ngành Trí tuệ Nhân tạo của trường Đại học FPT\n",
      "\n",
      "giúp sinh viên được cung cấp đầy đủ kiến thức và kỹ năng cần thiết để tỏa sáng\n",
      "\n",
      "trong lĩnh vực đầy tri thức này.\n",
      "\n",
      "3.  Chương trình đào tạo\n",
      "\n",
      "Chương trình học gồm 9 học kỳ, mỗi năm 3 học kỳ:\n",
      "\n",
      "Nền tảng: Sinh viên thông thạo kỹ năng đọc hiểu giáo trình Tiếng Anh,\n",
      "\n",
      "học tập và giao tiếp với giảng viên và sinh viên quốc tế.\n",
      "\n",
      "c)  Đào tạo nghiệp vụ ứng dụng xu hướng công nghệ\n",
      "\n",
      "Hướng đến xây dựng năng lực cho người học trở thành chuyên gia trong việc\n",
      "\n",
      "phân tích, hoạch định, quản trị và thực thi các hoạt động tài chính trong các lĩnh\n",
      "\n",
      "vực tài chính đầu tư và tài chính doanh nghiệp, cùng với xu thế của thời đại,\n",
      "\n",
      "chương trình chú trọng tiếp cận theo hướng công nghệ tài chính (Fintech). Sinh\n",
      "\n",
      "viên được trang bị kiến thức về lập trình, khoa học dữ liệu, trí tuệ nhân tạo,<|im_end|>\n",
      "<|im_start|>user\n",
      "Chương trình đào tạo của chuyên ngành trí tuệ nhân tạo?<|im_end|>\n",
      "<|im_start|>assitant\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\enviroments\\envs\\pytorch\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:671: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'query': 'Chương trình đào tạo của chuyên ngành trí tuệ nhân tạo?', 'result': '\\nChương trình đào tạo của chuyên ngành Trí tuệ Nhân tạo của trường Đại học FPT bao gồm các khóa học về các chủ đề như:\\n\\n1. Học máy, mạng thần kinh và xử lý ngôn ngữ tự nhiên\\n2. Kỹ thuật tính toán và phân tích dữ liệu\\n3. Kỹ thuật hình ảnh và robot\\n4. Học tăng cường và game AI\\n5. Hệ thống chuyên gia và kiến trúc kinh doanh thông minh\\n6. Kỹ thuật học sâu và mô hình dự đoán\\n7. Kỹ thuật xử lý ngôn ngữ tự nhiên và hiểu biết ngôn ngữ\\n8. Kỹ thuật thị giác máy tính và nhận dạng hình ảnh\\n9. Khoa học dữ liệu và kỹ thuật cơ sở dữ liệu\\n\\nChương trình đào tạo bao gồm một khóa học nền tảng, trong đó sinh viên được cung cấp kiến thức về lập trình, khoa học dữ liệu, trí tuệ nhân tạo và các chủ đề liên quan khác. Sau đó, sinh viên tiếp tục học các khóa học chuyên ngành, bao gồm các chủ đề cụ thể trong Trí tuệ Nhân tạo như Học máy, Kỹ thuật tính toán và phân tích dữ liệu, Hệ thống chuyên gia, v.v.\\n\\nNgoài ra, chương trình đào tạo còn bao gồm các yếu tố thực tế, như học cùng chuyên gia và doanh nghiệp đồng hành, dự án và học cùng chuyên gia, và học On The Job (Học việc trên Công việc).'}\n",
      "--- Inference time: 188.0299949645996 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "print(qa_chain.invoke(\"Chương trình đào tạo của chuyên ngành trí tuệ nhân tạo?\"))\n",
    "# print(device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "print(\"--- Inference time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4898c4c8-f9ae-4852-a891-4e8aef17bac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
